{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change to your project folder\n",
        "%cd /content/drive/MyDrive/prefflow-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R189shaNPHSG",
        "outputId": "0792081d-2f07-4f56-cd92-511e95456979"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/prefflow-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install normflows\n",
        "# !pip install hydra-core"
      ],
      "metadata": {
        "id": "u8T6oPTDeBvv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdQbAcNIIi3q"
      },
      "source": [
        "#### Imports ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oUFzPuCsIi3t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import normflows as nf\n",
        "import hydra\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from flows import RealNVP, NeuralSplineFlow\n",
        "from prefflow import PrefFlow\n",
        "from plotter import Plotter\n",
        "from target import set_up_problem\n",
        "from misc import convert_to_ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmQ8_UoDIi3u"
      },
      "source": [
        "#### Load config file to set-up experiment and algorithm details ####"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_root = \"/content/drive/MyDrive/prefflow-1\"\n",
        "os.chdir(project_root)\n",
        "print(\"Current directory:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwCI3KvPBnYt",
        "outputId": "e415bdab-75a2-4746-9b7d-bfa66c7cc476"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/drive/MyDrive/prefflow-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ReCd8yHyIi3u"
      },
      "outputs": [],
      "source": [
        "with hydra.initialize(\n",
        "    version_base=None,\n",
        "    config_path=\"../content/drive/MyDrive/prefflow-1/conf\"\n",
        "):\n",
        "    cfg = hydra.compose(config_name=\"config.yaml\")\n",
        "\n",
        "if not cfg.plot.showduringtraining:\n",
        "    matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSXwu_qAIi3u"
      },
      "source": [
        "#### Device and Precision ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7McMPJLOIi3v"
      },
      "outputs": [],
      "source": [
        "torch.set_default_dtype(torch.float64 if cfg.device.precision_double else torch.float32)\n",
        "device = torch.device(cfg.device.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQMKqeBJIi3v"
      },
      "source": [
        "#### Random seeds ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "sTnK7m2oIi3v"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "torch.manual_seed(cfg.exp.seed)\n",
        "np.random.seed(cfg.exp.seed)\n",
        "random.seed(cfg.exp.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZksJwCuIi3v"
      },
      "source": [
        "  #### Target belief density ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GUIVomv4Ii3v"
      },
      "outputs": [],
      "source": [
        "target_name = cfg.exp.target\n",
        "D = cfg.exp.d\n",
        "target, bounds, uniform, D, normalize = set_up_problem(target_name,D,device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNYvrdCKIi3v"
      },
      "source": [
        "#### Base distribution and Flow architecture ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "2qZuiX9sIi3v"
      },
      "outputs": [],
      "source": [
        "q0 = nf.distributions.DiagGaussian(D, trainable=False)\n",
        "nflows = cfg.params.nflows\n",
        "if cfg.params.flow == \"realnvp\":\n",
        "    nfm = RealNVP(nflows,D,q0,device,cfg.device.precision_double)\n",
        "if cfg.params.flow == \"neuralsplineflow\":\n",
        "    nfm = NeuralSplineFlow(nflows,D,q0,device,cfg.device.precision_double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaUD_oMfIi3w"
      },
      "source": [
        "#### Data generation 1/2 ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "i4-yrPDIIi3w"
      },
      "outputs": [],
      "source": [
        "target_sample = target.sample(10000).to(device)\n",
        "target_mean = target_sample.mean(dim=0).double().to(device)\n",
        "target_std = target_sample.std(dim=0).double().to(device)\n",
        "def sample_alternatives(n,k=2,distribution=\"uniform\"):\n",
        "        if distribution==\"uniform\":\n",
        "            x = uniform.sample(torch.tensor([k*n])).to(device)\n",
        "            return x\n",
        "        elif distribution==\"target\":\n",
        "            return target.sample(k*n).to(device)\n",
        "        elif distribution==\"mixture_uniform_gaussian\":\n",
        "            target_gaussian = torch.distributions.MultivariateNormal(target_mean, target_std*torch.eye(D, device=device))\n",
        "            howoftentarget = cfg.exp.mixture_success_prob\n",
        "            samples = []\n",
        "            for _ in range(k):\n",
        "                if np.random.sample() <= howoftentarget:\n",
        "                    x = target_gaussian.sample((n,)).to(device)\n",
        "                else:\n",
        "                    x = uniform.sample(torch.tensor([n])).to(device)\n",
        "                samples.append(x)\n",
        "            return torch.cat(samples, dim=0)\n",
        "def expert_feedback_pairwise(comp,s=None):\n",
        "    comp = comp.to(device)\n",
        "    noise = (0,0) if (s is None) else torch.distributions.Exponential(s).sample((2,)).to(device)\n",
        "    logprobs = target.log_prob(comp).to(device)\n",
        "    return torch.ge(logprobs[0] + noise[0],logprobs[1] + noise[1]).long().view(1).to(device)\n",
        "def expert_feedback_ranking(alternatives,s=None):\n",
        "    alternatives = alternatives.to(device)\n",
        "    k = alternatives.shape[0]\n",
        "    noise = torch.distributions.Exponential(s).sample((k,)).to(device)\n",
        "    logprobs = target.log_prob(alternatives) + noise\n",
        "    _, ranking_inds = torch.sort(logprobs, descending=True)\n",
        "    return ranking_inds.view(k).to(device)\n",
        "def generate_dataset(N,s=None,distribution=\"uniform\"):\n",
        "    X = sample_alternatives(1,2,distribution)\n",
        "    Y = expert_feedback_pairwise(X,s)\n",
        "    X = X.unsqueeze(2) #add new dimension, which indicates sample index\n",
        "    if N > 1:\n",
        "        for i in range(0,N-1):\n",
        "            comp = sample_alternatives(1,2,distribution)\n",
        "            X = torch.cat((X,comp.unsqueeze(2)),2)\n",
        "            Y = torch.cat((Y,expert_feedback_pairwise(comp,s)),0)\n",
        "    return X,Y #X.shape = (2,D,N) = (comp,space dimensions, number of comps)\n",
        "def generate_dataset_ranking(N,k,s=None,distribution=\"uniform\"):\n",
        "    X = sample_alternatives(1,k,distribution)\n",
        "    Y = expert_feedback_ranking(X,s).view(1,k)\n",
        "    X = X.unsqueeze(2) #add new dimension, which indicates sample index\n",
        "    if N > 1:\n",
        "        for i in range(0,N-1):\n",
        "            alternatives = sample_alternatives(1,k,distribution)\n",
        "            X = torch.cat((X,alternatives.unsqueeze(2)),2)\n",
        "            Y = torch.cat((Y,expert_feedback_ranking(alternatives,s).view(1,k)),0)\n",
        "    Xdata = convert_to_ranking(X.cpu().numpy(), Y.cpu().numpy())\n",
        "    #return X,Y #X.shape = (k,D,N) = (alternatives,space dimensions, number of rankings)\n",
        "    return torch.from_numpy(Xdata).view(k,-1,N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhoKowYQIi3w"
      },
      "source": [
        "#### Data generation 2/2 ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "DhFiF-VsIi3w"
      },
      "outputs": [],
      "source": [
        "n = cfg.data.n\n",
        "true_s = cfg.exp.true_s\n",
        "ranking = True if cfg.data.k > 2 else False\n",
        "if ranking:\n",
        "    k = cfg.data.k\n",
        "    dataset = generate_dataset_ranking(N=n,k=k,s=true_s,distribution=cfg.exp.lambda_dist).to(device)\n",
        "else:\n",
        "    dataset = generate_dataset(N=n,s=true_s,distribution=cfg.exp.lambda_dist).to(device)\n",
        "\n",
        "def minibatch(dataset,batch_size,ranking):\n",
        "    indices = torch.randperm(n)[:batch_size]\n",
        "    batch = (dataset[0][:,:,indices],dataset[1][indices]) if not ranking else dataset[:,:,indices]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SqWGUuHIi3w"
      },
      "source": [
        "  #### Initialize preferential flow ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "zpsYFISpIi3w"
      },
      "outputs": [],
      "source": [
        "prefflow = PrefFlow(nfm,D=D,s=cfg.modelparams.s,ranking=ranking,device=device,precision_double=cfg.device.precision_double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L3gIalLIi3x"
      },
      "source": [
        "#### Initialize optimizer ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "29uZRSFFIi3x"
      },
      "outputs": [],
      "source": [
        "loss_hist = np.array([])\n",
        "batch_size = cfg.params.batch_size\n",
        "optimizer = getattr(torch.optim, cfg.params.optimizer.capitalize())\n",
        "optimizer_prefflow = optimizer([{'params':prefflow.parameters()}],lr=cfg.params.lr, weight_decay=cfg.params.weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57tl2xJ-Ii3x"
      },
      "source": [
        "#### Initialize plotter ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "yFiVKW8sIi3x"
      },
      "outputs": [],
      "source": [
        "plotter = Plotter(D,bounds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-3xXc8tIi3x"
      },
      "source": [
        "### SGD FS-MAP ###"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Using device:\", device)\n",
        "\n",
        "# Check model\n",
        "print(\"PrefFlow on device:\", next(prefflow.parameters()).device)\n",
        "\n",
        "# Check a batch\n",
        "batch = minibatch(dataset, batch_size, ranking)\n",
        "if isinstance(batch, tuple):\n",
        "    print(\"Data batch device:\", batch[0].device)\n",
        "    print(\"Labels batch device:\", batch[1].device)\n",
        "else:\n",
        "    print(\"Ranking batch device:\", batch.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpxEWvKooMS3",
        "outputId": "c16bab60-82ee-4410-a70f-5c17a7c8903f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PrefFlow on device: cuda:0\n",
            "Ranking batch device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "7BhqKn1cIi3x",
        "outputId": "548f2762-7b24-4125-caf7-0f791e5f5066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension: 2\n",
            "Number of preferences 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 106/20000 [00:13<43:09,  7.68it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-56-3622669856.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mprefflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer_prefflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"Dimension:\", D)\n",
        "print(\"Number of preferences\", n)\n",
        "\n",
        "for it in tqdm(range(cfg.params.max_iter),disable=not cfg.plot.progressbar_show):\n",
        "\n",
        "    #Sample minibatch\n",
        "    batch = minibatch(dataset, batch_size, ranking)\n",
        "    #Update flow parameters\n",
        "    prefflow.train()\n",
        "    optimizer_prefflow.zero_grad()\n",
        "    loss = -prefflow.logposterior(batch,cfg.modelparams.weightprior)\n",
        "    if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
        "        loss.backward()\n",
        "        optimizer_prefflow.step()\n",
        "    loss_hist = np.append(loss_hist, loss.to('cpu').detach().numpy())\n",
        "\n",
        "    # Plot learned density\n",
        "    if (it + 1) % cfg.plot.show_iter == 0:\n",
        "        print(\"loss: \" + str(loss.to('cpu').detach().numpy()))\n",
        "        # if cfg.plot.showdatapoints:\n",
        "        #     showdata = minibatch(dataset,batch_size=n,ranking=ranking)\n",
        "        #     probmassinarea = plotter.plot_moon(target,prefflow,data=showdata,cfg=cfg)\n",
        "        # else:\n",
        "        #     probmassinarea = plotter.plot_moon(target,prefflow,data=None,cfg=cfg)\n",
        "        # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cyc3JcYQIi3y"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import kendalltau\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXwrhm9XIi3y"
      },
      "outputs": [],
      "source": [
        "# -------- 1. Plot Learning Curve --------\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(loss_hist, label='Training Loss')\n",
        "plt.title(f\"Training Loss (D={D}, n={n})\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJRKEW_GIi3y"
      },
      "outputs": [],
      "source": [
        "# -------- 2. Overlay PCA Projections: True vs. Learned --------\n",
        "# Sample from both true and learned distributions\n",
        "n_vis = 1000\n",
        "true_samples = target.sample(n_vis).detach().cpu().numpy()\n",
        "pnf_samples = prefflow.sample(n_vis)[0].detach().cpu().numpy()\n",
        "\n",
        "# Fit PCA on the combined data\n",
        "pca = PCA(n_components=2).fit(np.vstack([true_samples, pnf_samples]))\n",
        "true_proj = pca.transform(true_samples)\n",
        "pnf_proj = pca.transform(pnf_samples)\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.scatter(true_proj[:, 0], true_proj[:, 1], alpha=0.5, label=\"True\", s=10)\n",
        "plt.scatter(pnf_proj[:, 0], pnf_proj[:, 1], alpha=0.5, label=\"PNF\", s=10)\n",
        "plt.title(f\"PCA Projection: True vs. PNF Samples (D={D}, n={n})\")\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5cmWbW8Ii3y"
      },
      "outputs": [],
      "source": [
        "# -------- 3. KL Divergence Estimate (Monte Carlo) --------\n",
        "# KL(PNF || True): E_PNF [log q(x) - log p(x)]\n",
        "pnf_samples_torch = torch.from_numpy(pnf_samples).to(device)\n",
        "with torch.no_grad():\n",
        "    logq = prefflow.log_prob(pnf_samples_torch).detach().cpu().numpy()\n",
        "    logp = target.log_prob(pnf_samples_torch).detach().cpu().numpy()\n",
        "kl_estimate = np.mean(logq - logp)\n",
        "print(f\"Estimated KL(PNF || True) on PNF samples: {kl_estimate:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVtjMJ80Ii3y"
      },
      "outputs": [],
      "source": [
        "# -------- 4. Log-Likelihood of Held-Out Preferences --------\n",
        "# Generate held-out preference queries\n",
        "def heldout_log_likelihood(target, prefflow, n_queries=100, k=2):\n",
        "    ll_list = []\n",
        "    for _ in range(n_queries):\n",
        "        # Generate two alternatives from the uniform or true distribution\n",
        "        x = target.sample(k).to(device)\n",
        "        # True label (by true target)\n",
        "        logprobs = target.log_prob(x)\n",
        "        y_true = int(logprobs[0] > logprobs[1])\n",
        "        # Model predicted probabilities\n",
        "        logf, _ = prefflow.f(x)\n",
        "        prob_01 = torch.sigmoid(logf[0] - logf[1]).cpu().item()\n",
        "        ll = np.log(prob_01 if y_true else 1 - prob_01 + 1e-10)\n",
        "        ll_list.append(ll)\n",
        "    return np.mean(ll_list)\n",
        "\n",
        "heldout_ll = heldout_log_likelihood(target, prefflow, n_queries=100)\n",
        "print(f\"Mean log-likelihood on 100 held-out preferences: {heldout_ll:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqLg8Z6uIi3y"
      },
      "outputs": [],
      "source": [
        "# -------- 5. Ranking Consistency (Kendall tau) --------\n",
        "def ranking_consistency(target, prefflow, n_queries=50, k=5):\n",
        "    tau_list = []\n",
        "    for _ in range(n_queries):\n",
        "        x = target.sample(k).to(device)\n",
        "        u_true = target.log_prob(x).detach().cpu().numpy()\n",
        "        logf, _ = prefflow.f(x)\n",
        "        u_pred = logf.detach().cpu().numpy()\n",
        "        tau, _ = kendalltau(u_true, u_pred)\n",
        "        tau_list.append(tau)\n",
        "    return np.nanmean(tau_list)\n",
        "\n",
        "mean_tau = ranking_consistency(target, prefflow, n_queries=50, k=min(5, D))\n",
        "print(f\"Mean Kendall tau (ranking consistency, k=5): {mean_tau:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}