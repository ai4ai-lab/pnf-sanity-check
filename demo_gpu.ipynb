{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change to your project folder\n",
        "%cd /content/drive/MyDrive/prefflow-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R189shaNPHSG",
        "outputId": "16ad8eed-bddc-49cf-d0da-624b6f7f3974"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/prefflow-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install normflows\n",
        "# !pip install hydra-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8T6oPTDeBvv",
        "outputId": "5c91cdfb-c520-46c0-bebe-5c25908bea8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: normflows in /usr/local/lib/python3.11/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from normflows) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from normflows) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->normflows) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->normflows) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->normflows) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdQbAcNIIi3q"
      },
      "source": [
        "#### Imports ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oUFzPuCsIi3t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import normflows as nf\n",
        "import hydra\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from flows import RealNVP, NeuralSplineFlow\n",
        "from prefflow import PrefFlow\n",
        "from plotter import Plotter\n",
        "from target import set_up_problem\n",
        "from misc import convert_to_ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmQ8_UoDIi3u"
      },
      "source": [
        "#### Load config file to set-up experiment and algorithm details ####"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_root = \"/content/drive/MyDrive/prefflow-1\"\n",
        "os.chdir(project_root)\n",
        "print(\"Current directory:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwCI3KvPBnYt",
        "outputId": "8bd44800-c922-4bfd-a5d6-4f015db4142f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/drive/MyDrive/prefflow-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ReCd8yHyIi3u"
      },
      "outputs": [],
      "source": [
        "with hydra.initialize(\n",
        "    version_base=None,\n",
        "    config_path=\"../content/drive/MyDrive/prefflow-1/conf\"\n",
        "):\n",
        "    cfg = hydra.compose(config_name=\"config.yaml\")\n",
        "\n",
        "if not cfg.plot.showduringtraining:\n",
        "    matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSXwu_qAIi3u"
      },
      "source": [
        "#### Device and Precision ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7McMPJLOIi3v"
      },
      "outputs": [],
      "source": [
        "torch.set_default_dtype(torch.float64 if cfg.device.precision_double else torch.float32)\n",
        "device = torch.device(cfg.device.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQMKqeBJIi3v"
      },
      "source": [
        "#### Random seeds ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sTnK7m2oIi3v"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "torch.manual_seed(cfg.exp.seed)\n",
        "np.random.seed(cfg.exp.seed)\n",
        "random.seed(cfg.exp.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZksJwCuIi3v"
      },
      "source": [
        "  #### Target belief density ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GUIVomv4Ii3v"
      },
      "outputs": [],
      "source": [
        "target_name = cfg.exp.target\n",
        "D = cfg.exp.d\n",
        "target, bounds, uniform, D, normalize = set_up_problem(target_name,D,device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNYvrdCKIi3v"
      },
      "source": [
        "#### Base distribution and Flow architecture ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2qZuiX9sIi3v"
      },
      "outputs": [],
      "source": [
        "q0 = nf.distributions.DiagGaussian(D, trainable=False)\n",
        "nflows = cfg.params.nflows\n",
        "if cfg.params.flow == \"realnvp\":\n",
        "    nfm = RealNVP(nflows,D,q0,device,cfg.device.precision_double)\n",
        "if cfg.params.flow == \"neuralsplineflow\":\n",
        "    nfm = NeuralSplineFlow(nflows,D,q0,device,cfg.device.precision_double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaUD_oMfIi3w"
      },
      "source": [
        "#### Data generation 1/2 ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "i4-yrPDIIi3w"
      },
      "outputs": [],
      "source": [
        "target_sample = target.sample(10000)\n",
        "target_mean = target_sample.mean(dim=0).double()\n",
        "target_std = target_sample.std(dim=0).double()\n",
        "def sample_alternatives(n,k=2,distribution=\"uniform\"):\n",
        "        if distribution==\"uniform\":\n",
        "            x = uniform.sample(torch.tensor([k*n])).to(device)\n",
        "            return x\n",
        "        elif distribution==\"target\":\n",
        "            return target.sample(k*n).to(device)\n",
        "        elif distribution==\"mixture_uniform_gaussian\":\n",
        "            target_gaussian = torch.distributions.MultivariateNormal(target_mean, target_std*torch.eye(D))\n",
        "            howoftentarget = cfg.exp.mixture_success_prob\n",
        "            samples = []\n",
        "            for _ in range(k):\n",
        "                if np.random.sample() <= howoftentarget:\n",
        "                    x = target_gaussian.sample((n,)).to(device)\n",
        "                else:\n",
        "                    x = uniform.sample(torch.tensor([n])).to(device)\n",
        "                samples.append(x)\n",
        "            return torch.cat(samples, dim=0)\n",
        "def expert_feedback_pairwise(comp,s=None):\n",
        "    comp = comp.to(device)\n",
        "    noise = (0,0) if (s is None) else torch.distributions.Exponential(s).sample((2,)).to(device)\n",
        "    logprobs = target.log_prob(comp).to(device)\n",
        "    return torch.ge(logprobs[0] + noise[0],logprobs[1] + noise[1]).long().view(1).to(device)\n",
        "def expert_feedback_ranking(alternatives,s=None):\n",
        "    alternatives = alternatives.to(device)\n",
        "    k = alternatives.shape[0]\n",
        "    noise = torch.distributions.Exponential(s).sample((k,)).to(device)\n",
        "    logprobs = target.log_prob(alternatives) + noise\n",
        "    _, ranking_inds = torch.sort(logprobs, descending=True)\n",
        "    return ranking_inds.view(k).to(device)\n",
        "def generate_dataset(N,s=None,distribution=\"uniform\"):\n",
        "    X = sample_alternatives(1,2,distribution)\n",
        "    Y = expert_feedback_pairwise(X,s)\n",
        "    X = X.unsqueeze(2) #add new dimension, which indicates sample index\n",
        "    if N > 1:\n",
        "        for i in range(0,N-1):\n",
        "            comp = sample_alternatives(1,2,distribution)\n",
        "            X = torch.cat((X,comp.unsqueeze(2)),2)\n",
        "            Y = torch.cat((Y,expert_feedback_pairwise(comp,s)),0)\n",
        "    return X,Y #X.shape = (2,D,N) = (comp,space dimensions, number of comps)\n",
        "def generate_dataset_ranking(N,k,s=None,distribution=\"uniform\"):\n",
        "    X = sample_alternatives(1,k,distribution)\n",
        "    Y = expert_feedback_ranking(X,s).view(1,k)\n",
        "    X = X.unsqueeze(2) #add new dimension, which indicates sample index\n",
        "    if N > 1:\n",
        "        for i in range(0,N-1):\n",
        "            alternatives = sample_alternatives(1,k,distribution)\n",
        "            X = torch.cat((X,alternatives.unsqueeze(2)),2)\n",
        "            Y = torch.cat((Y,expert_feedback_ranking(alternatives,s).view(1,k)),0)\n",
        "    Xdata = convert_to_ranking(X.numpy(),Y.numpy())\n",
        "    #return X,Y #X.shape = (k,D,N) = (alternatives,space dimensions, number of rankings)\n",
        "    return torch.from_numpy(Xdata).view(k,-1,N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhoKowYQIi3w"
      },
      "source": [
        "#### Data generation 2/2 ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DhFiF-VsIi3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "3359ab30-4cbe-4a88-d911-fd0879e15c00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-59110978.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mranking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dataset_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-23-3175189481.py\u001b[0m in \u001b[0;36mgenerate_dataset_ranking\u001b[0;34m(N, k, s, distribution)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;31m#X.shape = (2,D,N) = (comp,space dimensions, number of comps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_dataset_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_alternatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpert_feedback_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#add new dimension, which indicates sample index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-23-3175189481.py\u001b[0m in \u001b[0;36msample_alternatives\u001b[0;34m(n, k, distribution)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"mixture_uniform_gaussian\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtarget_gaussian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_std\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mhowoftentarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture_success_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "n = cfg.data.n\n",
        "true_s = cfg.exp.true_s\n",
        "ranking = True if cfg.data.k > 2 else False\n",
        "if ranking:\n",
        "    k = cfg.data.k\n",
        "    dataset = generate_dataset_ranking(N=n,k=k,s=true_s,distribution=cfg.exp.lambda_dist)\n",
        "else:\n",
        "    dataset = generate_dataset(N=n,s=true_s,distribution=cfg.exp.lambda_dist)\n",
        "\n",
        "def minibatch(dataset,batch_size,ranking):\n",
        "    indices = torch.randperm(n)[:batch_size]\n",
        "    batch = (dataset[0][:,:,indices],dataset[1][indices]) if not ranking else dataset[:,:,indices]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SqWGUuHIi3w"
      },
      "source": [
        "  #### Initialize preferential flow ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpsYFISpIi3w"
      },
      "outputs": [],
      "source": [
        "prefflow = PrefFlow(nfm,D=D,s=cfg.modelparams.s,ranking=ranking,device=device,precision_double=cfg.device.precision_double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L3gIalLIi3x"
      },
      "source": [
        "#### Initialize optimizer ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29uZRSFFIi3x"
      },
      "outputs": [],
      "source": [
        "loss_hist = np.array([])\n",
        "batch_size = cfg.params.batch_size\n",
        "optimizer = getattr(torch.optim, cfg.params.optimizer.capitalize())\n",
        "optimizer_prefflow = optimizer([{'params':prefflow.parameters()}],lr=cfg.params.lr, weight_decay=cfg.params.weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57tl2xJ-Ii3x"
      },
      "source": [
        "#### Initialize plotter ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFiVKW8sIi3x"
      },
      "outputs": [],
      "source": [
        "plotter = Plotter(D,bounds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-3xXc8tIi3x"
      },
      "source": [
        "### SGD FS-MAP ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BhqKn1cIi3x"
      },
      "outputs": [],
      "source": [
        "print(\"Dimension:\", D)\n",
        "print(\"Number of preferences\", n)\n",
        "\n",
        "for it in tqdm(range(cfg.params.max_iter),disable=not cfg.plot.progressbar_show):\n",
        "\n",
        "    #Sample minibatch\n",
        "    batch = minibatch(dataset,batch_size,ranking)\n",
        "    #Update flow parameters\n",
        "    prefflow.train()\n",
        "    optimizer_prefflow.zero_grad()\n",
        "    loss = -prefflow.logposterior(batch,cfg.modelparams.weightprior)\n",
        "    if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
        "        loss.backward()\n",
        "        optimizer_prefflow.step()\n",
        "    loss_hist = np.append(loss_hist, loss.to('cpu').detach().numpy())\n",
        "\n",
        "    # Plot learned density\n",
        "    if (it + 1) % cfg.plot.show_iter == 0:\n",
        "        print(\"loss: \" + str(loss.to('cpu').detach().numpy()))\n",
        "        # if cfg.plot.showdatapoints:\n",
        "        #     showdata = minibatch(dataset,batch_size=n,ranking=ranking)\n",
        "        #     probmassinarea = plotter.plot_moon(target,prefflow,data=showdata,cfg=cfg)\n",
        "        # else:\n",
        "        #     probmassinarea = plotter.plot_moon(target,prefflow,data=None,cfg=cfg)\n",
        "        # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cyc3JcYQIi3y"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import kendalltau\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXwrhm9XIi3y"
      },
      "outputs": [],
      "source": [
        "# -------- 1. Plot Learning Curve --------\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(loss_hist, label='Training Loss')\n",
        "plt.title(f\"Training Loss (D={D}, n={n})\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJRKEW_GIi3y"
      },
      "outputs": [],
      "source": [
        "# -------- 2. Overlay PCA Projections: True vs. Learned --------\n",
        "# Sample from both true and learned distributions\n",
        "n_vis = 1000\n",
        "true_samples = target.sample(n_vis).detach().cpu().numpy()\n",
        "pnf_samples = prefflow.sample(n_vis)[0].detach().cpu().numpy()\n",
        "\n",
        "# Fit PCA on the combined data\n",
        "pca = PCA(n_components=2).fit(np.vstack([true_samples, pnf_samples]))\n",
        "true_proj = pca.transform(true_samples)\n",
        "pnf_proj = pca.transform(pnf_samples)\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.scatter(true_proj[:, 0], true_proj[:, 1], alpha=0.5, label=\"True\", s=10)\n",
        "plt.scatter(pnf_proj[:, 0], pnf_proj[:, 1], alpha=0.5, label=\"PNF\", s=10)\n",
        "plt.title(f\"PCA Projection: True vs. PNF Samples (D={D}, n={n})\")\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5cmWbW8Ii3y"
      },
      "outputs": [],
      "source": [
        "# -------- 3. KL Divergence Estimate (Monte Carlo) --------\n",
        "# KL(PNF || True): E_PNF [log q(x) - log p(x)]\n",
        "pnf_samples_torch = torch.from_numpy(pnf_samples).to(device)\n",
        "with torch.no_grad():\n",
        "    logq = prefflow.log_prob(pnf_samples_torch).detach().cpu().numpy()\n",
        "    logp = target.log_prob(pnf_samples_torch).detach().cpu().numpy()\n",
        "kl_estimate = np.mean(logq - logp)\n",
        "print(f\"Estimated KL(PNF || True) on PNF samples: {kl_estimate:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVtjMJ80Ii3y"
      },
      "outputs": [],
      "source": [
        "# -------- 4. Log-Likelihood of Held-Out Preferences --------\n",
        "# Generate held-out preference queries\n",
        "def heldout_log_likelihood(target, prefflow, n_queries=100, k=2):\n",
        "    ll_list = []\n",
        "    for _ in range(n_queries):\n",
        "        # Generate two alternatives from the uniform or true distribution\n",
        "        x = target.sample(k).to(device)\n",
        "        # True label (by true target)\n",
        "        logprobs = target.log_prob(x)\n",
        "        y_true = int(logprobs[0] > logprobs[1])\n",
        "        # Model predicted probabilities\n",
        "        logf, _ = prefflow.f(x)\n",
        "        prob_01 = torch.sigmoid(logf[0] - logf[1]).cpu().item()\n",
        "        ll = np.log(prob_01 if y_true else 1 - prob_01 + 1e-10)\n",
        "        ll_list.append(ll)\n",
        "    return np.mean(ll_list)\n",
        "\n",
        "heldout_ll = heldout_log_likelihood(target, prefflow, n_queries=100)\n",
        "print(f\"Mean log-likelihood on 100 held-out preferences: {heldout_ll:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqLg8Z6uIi3y"
      },
      "outputs": [],
      "source": [
        "# -------- 5. Ranking Consistency (Kendall tau) --------\n",
        "def ranking_consistency(target, prefflow, n_queries=50, k=5):\n",
        "    tau_list = []\n",
        "    for _ in range(n_queries):\n",
        "        x = target.sample(k).to(device)\n",
        "        u_true = target.log_prob(x).detach().cpu().numpy()\n",
        "        logf, _ = prefflow.f(x)\n",
        "        u_pred = logf.detach().cpu().numpy()\n",
        "        tau, _ = kendalltau(u_true, u_pred)\n",
        "        tau_list.append(tau)\n",
        "    return np.nanmean(tau_list)\n",
        "\n",
        "mean_tau = ranking_consistency(target, prefflow, n_queries=50, k=min(5, D))\n",
        "print(f\"Mean Kendall tau (ranking consistency, k=5): {mean_tau:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}